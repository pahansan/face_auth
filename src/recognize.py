import os

import cv2

# ========== 1. –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô ==========

# DNN-–º–æ–¥–µ–ª—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ª–∏—Ü
faceProto = "opencv_face_detector.pbtxt"
faceModel = "opencv_face_detector_uint8.pb"
faceNet = cv2.dnn.readNet(faceModel, faceProto)

# LBPH-–º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–æ–±—É—á–µ–Ω–Ω–∞—è –≤–∞–º–∏)
recognizer = cv2.face.LBPHFaceRecognizer_create()

# –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
path = os.path.dirname(os.path.abspath(__file__))
trainer_path = os.path.join(path, 'trainer', 'trainer.yml')
trainer_path = 'trainer/trainer.yml'

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
if not os.path.exists(trainer_path):
    print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª {trainer_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è!")
    exit()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
recognizer.read(trainer_path)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# ========== 2. –ù–ê–°–¢–†–û–ô–ö–ò ==========

# –°–ª–æ–≤–∞—Ä—å ID -> –ò–º—è (–∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Å–≤–æ–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏!)
# –ù–∞–ø—Ä–∏–º–µ—Ä: {1: "–ò–≤–∞–Ω", 2: "–ú–∞—Ä–∏—è"}
names = {
    1: "Pashka",
    2: "User_2",
    3: "User_3",
    # –î–æ–±–∞–≤—å—Ç–µ —Å—é–¥–∞ ID –∏ –∏–º–µ–Ω–∞ –∏–∑ –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
}

# –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (—á–µ–º –ú–ï–ù–¨–®–ï, —Ç–µ–º —Å—Ç—Ä–æ–∂–µ. LBPH –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç "—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ")
# –û–ø—Ç–∏–º–∞–ª—å–Ω–æ: 50-80. –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π - —É–º–µ–Ω—å—à–∏—Ç–µ
CONFIDENCE_THRESHOLD = 70

# –û—Ç—Å—Ç—É–ø –≤–æ–∫—Ä—É–≥ –ª–∏—Ü–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
PADDING = 20

# ========== 3. –§–£–ù–ö–¶–ò–ò ==========

def highlightFace(net, frame, conf_threshold=0.7):
    """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ª–∏—Ü–∞ —Å –ø–æ–º–æ—â—å—é DNN"""
    frameOpencvDnn = frame.copy()
    frameHeight, frameWidth = frameOpencvDnn.shape[:2]

    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)
    net.setInput(blob)
    detections = net.forward()

    faceBoxes = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > conf_threshold:
            x1 = int(detections[0, 0, i, 3] * frameWidth)
            y1 = int(detections[0, 0, i, 4] * frameHeight)
            x2 = int(detections[0, 0, i, 5] * frameWidth)
            y2 = int(detections[0, 0, i, 6] * frameHeight)
            faceBoxes.append([x1, y1, x2, y2])

    return frameOpencvDnn, faceBoxes

# ========== 4. –ó–ê–ü–£–°–ö –í–ò–î–ï–û ==========

video = cv2.VideoCapture(0)

if not video.isOpened():
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
    exit()

print("üìπ –ö–∞–º–µ—Ä–∞ –∑–∞–ø—É—â–µ–Ω–∞. –ù–∞–∂–º–∏—Ç–µ 'Q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")

while True:
    hasFrame, frame = video.read()
    if not hasFrame:
        break

    # –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –ª–∏—Ü–∞
    resultImg, faceBoxes = highlightFace(faceNet, frame, conf_threshold=0.2)

    if not faceBoxes:
        cv2.putText(resultImg, "–õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    else:
        # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º –∫–∞–∂–¥–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
        for faceBox in faceBoxes:
            x1, y1, x2, y2 = faceBox

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
            x1_pad = max(0, x1 - PADDING)
            y1_pad = max(0, y1 - PADDING)
            x2_pad = min(frame.shape[1], x2 + PADDING)
            y2_pad = min(frame.shape[0], y2 + PADDING)

            # –í—ã—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
            face_roi = frame[y1_pad:y2_pad, x1_pad:x2_pad]
            if face_roi.size == 0:
                continue

            gray_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)

            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            label_id, confidence = recognizer.predict(gray_roi)

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            if confidence < CONFIDENCE_THRESHOLD:
                name = names.get(label_id, f"ID:{label_id}")
                text = f"{name} ({int(confidence)})"
                color = (0, 255, 0)  # –ó–µ–ª—ë–Ω—ã–π
            else:
                text = "Unknown"
                color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π

            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –∏ —Ç–µ–∫—Å—Ç
            cv2.rectangle(resultImg, (x1, y1), (x2, y2), color, 2)
            cv2.putText(resultImg, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    cv2.imshow("Face detection and recognition", resultImg)

    # –í—ã—Ö–æ–¥ –ø–æ Q
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ========== 5. –û–ß–ò–°–¢–ö–ê ==========
video.release()
cv2.destroyAllWindows()
print("üëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
